<!DOCTYPE html >
<head> 
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
  <title>HIP2.htm Gabriel Dauphin </title>
</head>
<body>
<p style="text-align:right;">Gabriel Dauphin (<a href="http://gabrieldauphin.neocities.org">web page</a>)</p>

<h2><font color="#339966">
Hyperspectral Image Processing </font></h2>

<h4> Presentation of the lectures </h4>
<p>
Hyperspectral images are now available for a wide range of applications: monitoring, mapping or helping with disaster management.<br>
A major challenge lies in the interpretation of these images, a task which is referred to in computer science as the classification of images. For each pixel, we are provided with a set of intensities, one for each bandwidth. These intensities are somehow related to the surface reflectance and hence to the type of land cover or of land use. And instead of being able to model precisely this extremely complex relationship between intensities and interpretation, the scientific literature provides an abundance of techniques to capture information from the data themselves with the help of the ground truth.<br>
These lectures aim at describing some of these techniques: what are their objectives, what kind of information they use, how reliable are their predictions? To study these techniques, we will consider toy examples, sometimes get involved in the mathematical technicalities and sometimes consider simple algorithms. Some ideas developed in these lectures come from textbooks for university students, many others stem from research papers and related questions.<br>
I would expect these lectures to help getting more familiar with how proposed techniques are described in research papers. Throughout these lectures we will consider in the context of binary classification of hyperspectral images the following issues: learning regarded as an optimization problem, can we be positive about machine learning predictions, why is there a need for some strange concepts? We will have a look at some segmentation issues stemming from the computer vision community.<br>
</p>

<h4> Material </h4>
<ul>
<li> Notebook (only started) with in appendix, all exercises and all Octave/Matlab code to yield the displayed figures in the slides
<a href="lecture_notes2.pdf"> lecture_notes2.pdf </a> </li>
<li> Slides used during the lecture 
<a href="mlCl_slides2.pdf"> mlCl_slides2.pdf</a>
</li>
<ul>

 

<h4> First lecture (March 13th 2024) </h4>
<ul> <li>
            Link to video <a href="https://drive.google.com/file/d/1E0U2Gq9LBt6NlyVbMES62bNBvSoQPSaM/view"> HIP2_lesson_1.mp4</a>
</li>
</ul>

<h4> Second lecture (March 14th 2024) </h4>
<ul> <li>
            Link to video <a href="https://drive.google.com/file/d/1GQN3D8dZFoNScM4XHoiF2-Ah79Y2liNy/view"> HIP2_lesson_2.mp4</a>
</li>
</ul>

<h4> Third lecture (March 15th 2024) </h4>
<ul> <li>
            Link to video <a href="https://drive.google.com/file/d/11BueRXgNm_qwpFDEeKB_JCLCApRMRY-5/view"> HIP2_lesson_3.mp4</a>
</li>
</ul>

<h4> Fourth lecture (March 16th 2024) </h4>
<ul> <li>
            Link to video <a href="https://drive.google.com/file/d/1oJJbWjKf6VnWINC1h-7T2L0hdUCVcUq2/view"> HIP2_lesson_4.mp4</a>
</li>
</ul>

</body> 

